# ğŸ§  í¬íŠ¸í´ë¦¬ì˜¤: TensorFlow ì‹ ê²½ë§ ê¸°ì´ˆ ë° ìµœì í™” ê¸°ë²•

**TensorFlow/Kerasë¥¼ í™œìš©í•œ ì‹ ê²½ë§ì˜ í•µì‹¬ ê°œë…ë¶€í„° ê³ ê¸‰ ìµœì í™”ê¹Œì§€ ì‹¤ìŠµí•˜ê³  êµ¬í˜„í•œ í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤.**

---

## ğŸ“– ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±](#í¬íŠ¸í´ë¦¬ì˜¤-êµ¬ì„±)
- [ì£¼ìš” í•™ìŠµ ë‚´ìš©](#ì£¼ìš”-í•™ìŠµ-ë‚´ìš©)
- [ì„¤ì¹˜ ë° ì‹¤í–‰](#ì„¤ì¹˜-ë°-ì‹¤í–‰)
- [í´ë” êµ¬ì¡°](#í´ë”-êµ¬ì¡°)
- [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
- [ì£¼ìš” ì„±ê³¼](#ì£¼ìš”-ì„±ê³¼)
- [í–¥í›„ í•™ìŠµ ê³„íš](#í–¥í›„-í•™ìŠµ-ê³„íš)
- [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

---

## ê°œìš”

ì´ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” **ì‹ ê²½ë§ì˜ ê¸°ì´ˆë¶€í„° ì‹¤ì „ ìµœì í™” ê¸°ë²•**ê¹Œì§€ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  êµ¬í˜„í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

### í•µì‹¬ í•™ìŠµ ì˜ì—­

- **íšŒê·€(Regression)**: ë‹¤ì–‘í•œ ì†ì‹¤í•¨ìˆ˜ì˜ íŠ¹ì„± ë° ì ìš©
- **ë¶„ë¥˜(Classification)**: ì´ì§„ ë¶„ë¥˜, ë‹¤ì¤‘ í´ë˜ìŠ¤, ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜
- **ê³ ê¸‰ ê¸°ë²•**: ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤, ì”ì°¨ ë„¤íŠ¸ì›Œí¬, ì •ê·œí™”, Dropout, ë°ì´í„° ì¦ê°•

### ëŒ€ìƒ ë…ì

- ì‹ ê²½ë§ ê¸°ì´ˆë¥¼ ê³µë¶€í•˜ëŠ” í•™ìƒ ë° ê°œë°œì
- ë”¥ëŸ¬ë‹ ì‹¤ë¬´ì—ì„œ ê° ê¸°ë²•ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ê³  ì‹¶ì€ ì—”ì§€ë‹ˆì–´
- ë°ì´í„° ê³¼í•™ í”„ë¡œì íŠ¸ì— ì‹ ê²½ë§ ì ìš©ì„ ê³ ë ¤ ì¤‘ì¸ ë¶„ì„ê°€

---

## í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±

ì´ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” **3ê°œì˜ ì£¼ìš” ì„¹ì…˜**ê³¼ **12ê°œì˜ ì‹¤ìŠµ ë…¸íŠ¸ë¶**ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### ğŸ“Š ì„¹ì…˜ë³„ ê°œìš”

```
Portfolio-DeepLearning-Fundamentals/
â”œâ”€â”€ 1_Regression/              â†’ íšŒê·€ ëª¨ë¸ ë° ì†ì‹¤í•¨ìˆ˜
â”œâ”€â”€ 2_Classification/          â†’ ë¶„ë¥˜ ëª¨ë¸ (ì´ì§„/ë‹¤ì¤‘ í´ë˜ìŠ¤)
â”œâ”€â”€ 3_Advanced_Techniques/     â†’ ê³ ê¸‰ ìµœì í™” ë° ì •ê·œí™”
â”œâ”€â”€ assets/                    â†’ ì‹œê°í™” ë° ë‹¤ì´ì–´ê·¸ë¨
â””â”€â”€ REPORT.md                  â†’ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
```

---

## ì£¼ìš” í•™ìŠµ ë‚´ìš©

### 1ï¸âƒ£ íšŒê·€ (Regression)

#### ğŸ““ 1.1 ì†ì‹¤í•¨ìˆ˜ ë¹„êµ ë¶„ì„
**íŒŒì¼**: `1_Regression/1.1_loss_comparison/nn_regression_loss_comparison.ipynb`

ì‹ ê²½ë§ íšŒê·€ ëª¨ë¸ì—ì„œ **ë‹¤ì–‘í•œ ì†ì‹¤í•¨ìˆ˜ì˜ íŠ¹ì„±**ì„ ë¹„êµí•©ë‹ˆë‹¤.

**ë‹¤ë£¬ ì†ì‹¤í•¨ìˆ˜:**
- **MSE (Mean Squared Error)**
  - íŠ¹ì§•: í° ì˜¤ì°¨ì— ë” í° í˜ë„í‹° ë¶€ì—¬
  - í™œìš©: ì¼ë°˜ì ì¸ íšŒê·€ ë¬¸ì œ, ì´ìƒì¹˜ì— ë¯¼ê°í•¨
  - ìˆ˜ì‹: L = (1/n) Î£(Å· - y)Â²

- **MAE (Mean Absolute Error)**
  - íŠ¹ì§•: ëª¨ë“  ì˜¤ì°¨ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜
  - í™œìš©: ì´ìƒì¹˜ê°€ ë§ì€ ë°ì´í„°, ê°•ê±´ì„± ì¤‘ìš”
  - ìˆ˜ì‹: L = (1/n) Î£|Å· - y|

- **Huber Loss**
  - íŠ¹ì§•: MSEì™€ MAEì˜ ì¥ì  ê²°í•©
  - í™œìš©: ì´ìƒì¹˜ì™€ ì¼ë°˜ ë°ì´í„° í˜¼ì¬
  - ì„±ëŠ¥: MSEì™€ MAE ì‚¬ì´ì˜ ì¤‘ê°„ íŠ¹ì„±

**ì£¼ìš” ì‹¤í—˜:**
- ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ (8ê°œ íŠ¹ì„±, 20,640ê°œ ìƒ˜í”Œ)
- ê° ì†ì‹¤í•¨ìˆ˜ë³„ í•™ìŠµ ê³¡ì„  ë¶„ì„
- ê²€ì¦ ì„±ëŠ¥ ë° ìˆ˜ë ´ ì†ë„ ë¹„êµ

**ê¸°ëŒ€ íš¨ê³¼:**
```
MSE ê²€ì¦ ì†ì‹¤: 0.29 (ì•ˆì •ì )
MAE ê²€ì¦ ì†ì‹¤: 0.38 (ê°•ê±´í•¨)
Huber ê²€ì¦ ì†ì‹¤: 0.31 (ê· í˜•ì¡í˜)
```

---

### 2ï¸âƒ£ ë¶„ë¥˜ (Classification)

#### ğŸ““ 2.1 ì´ì§„ ë¶„ë¥˜ & ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜
**íŒŒì¼**: 
- `2_Classification/2.1_binary_multiclass/nn_classification_examples.ipynb`
- `2_Classification/2.1_binary_multiclass/nn_multiclass_classification.ipynb`

**ì´ì§„ ë¶„ë¥˜ (Binary Classification)**
- ë°ì´í„°ì…‹: sklearn `make_classification` (1000ê°œ ìƒ˜í”Œ, 20ê°œ íŠ¹ì„±)
- ì¶œë ¥ì¸µ: Sigmoid í™œì„±í™” í•¨ìˆ˜ (í™•ë¥ ê°’ 0~1)
- ì†ì‹¤í•¨ìˆ˜: Binary Crossentropy
- ì„±ëŠ¥: ~95% ì •í™•ë„ ë‹¬ì„±

**ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ (Multiclass Classification)**
- ë°ì´í„°ì…‹: MNIST ì†ê¸€ì”¨ ìˆ«ì (0~9)
- í•™ìŠµ ë°ì´í„°: 60,000ê°œ ìƒ˜í”Œ (28Ã—28 ì´ë¯¸ì§€)
- í…ŒìŠ¤íŠ¸ ë°ì´í„°: 10,000ê°œ ìƒ˜í”Œ
- ì¶œë ¥ì¸µ: Softmax í™œì„±í™” í•¨ìˆ˜ (10ê°œ í´ë˜ìŠ¤)
- ì†ì‹¤í•¨ìˆ˜: Categorical Crossentropy
- ì„±ëŠ¥: ~97% ì •í™•ë„ ë‹¬ì„±

**í•µì‹¬ ê¸°ë²•:**
```python
# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ì•„í‚¤í…ì²˜ ì˜ˆì‹œ
model = Sequential([
    InputLayer(input_shape=(784,)),      # 28Ã—28 = 784
    Dense(128, activation='relu'),       # ì€ë‹‰ì¸µ 1
    Dense(128, activation='relu'),       # ì€ë‹‰ì¸µ 2
    Dense(10, activation='softmax')      # ì¶œë ¥ì¸µ (10ê°œ í´ë˜ìŠ¤)
])
```

---

### 3ï¸âƒ£ ê³ ê¸‰ ê¸°ë²• (Advanced Techniques)

#### ğŸ““ 3.1 ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œ (Vanishing Gradient Problem)
**íŒŒì¼**: `3_Advanced_Techniques/3.1_vanishing_gradient/vanishing_gradient_demo.ipynb`

**ë¬¸ì œ ì •ì˜:**
ì‹ ê²½ë§ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ì—­ì „íŒŒ ê³¼ì •ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì§€ìˆ˜ì ìœ¼ë¡œ ê°ì†Œí•˜ëŠ” í˜„ìƒ

**ì›ì¸ ë¶„ì„:**
- Sigmoid í™œì„±í™” í•¨ìˆ˜ì˜ ë„í•¨ìˆ˜ ë²”ìœ„: 0~0.25
- ê¹Šì€ ì‹ ê²½ë§ì—ì„œ ì—°ì‡„ë²•ì¹™ ì ìš© ì‹œ ê·¹ë„ë¡œ ì‘ì€ ê·¸ë˜ë””ì–¸íŠ¸ ë°œìƒ
- ì•ìª½ ì¸µì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ê±°ì˜ ì¼ì–´ë‚˜ì§€ ì•ŠìŒ

**í•´ê²°ì±… ì‹¤í—˜:**
- ReLU í™œì„±í™” í•¨ìˆ˜ ë„ì… (ë„í•¨ìˆ˜: 0 ë˜ëŠ” 1)
- ê²°ê³¼: ê¹Šì€ ì‹ ê²½ë§ë„ íš¨ìœ¨ì  í•™ìŠµ ê°€ëŠ¥

**ì‹¤ìŠµ ë‚´ìš©:**
```
ì‹¤í—˜ 1: ê¹Šì€ ì‹ ê²½ë§ (10ì¸µ) + Sigmoid
- ì´ˆê¸° ì¸µ ê·¸ë˜ë””ì–¸íŠ¸: ~0.00001
- í•™ìŠµ ë¶ˆì•ˆì •, ìˆ˜ë ´ ì–´ë ¤ì›€

ì‹¤í—˜ 2: ê¹Šì€ ì‹ ê²½ë§ (10ì¸µ) + ReLU
- ì´ˆê¸° ì¸µ ê·¸ë˜ë””ì–¸íŠ¸: ~0.01
- ì•ˆì •ì  ìˆ˜ë ´, ë†’ì€ ì •í™•ë„ ë‹¬ì„±
```

---

#### ğŸ““ 3.2 ì”ì°¨ ë„¤íŠ¸ì›Œí¬ (Residual Networks)
**íŒŒì¼**: `3_Advanced_Techniques/3.2_residual_networks/residual_vs_plain_demo.ipynb`

**ê°œë…:**
Skip connectionì„ í†µí•´ ì…ë ¥ì„ ì§ì ‘ ì—¬ëŸ¬ ì¸µ ì´í›„ì˜ ì ì— ì „ë‹¬

**êµ¬ì¡° ë¹„êµ:**

| êµ¬ì„± | ì¼ë°˜ ì‹ ê²½ë§ | ì”ì°¨ ì‹ ê²½ë§ |
|------|-----------|-----------|
| ê²½ë¡œ | x â†’ Dense â†’ Dense â†’ y | x â†’ Dense â†’ Dense â†’ y + x |
| í•™ìŠµ ëŒ€ìƒ | ì „ì²´ í•¨ìˆ˜ | ì”ì°¨ (F(x) = y - x) |
| ê·¸ë˜ë””ì–¸íŠ¸ | ì†Œì‹¤ ê°€ëŠ¥ì„± | ì§ì ‘ ê²½ë¡œë¡œ ì•ˆì •í™” |
| ê¹Šì´ | ì œí•œì  | ë§¤ìš° ê¹Šì€ êµ¬ì¡° ê°€ëŠ¥ (152ì¸µ+) |

**ì‹¤í—˜ ê²°ê³¼:**
```
ì¼ë°˜ ì‹ ê²½ë§ (20ì¸µ):   ê²€ì¦ ì†ì‹¤ 0.35
ì”ì°¨ ì‹ ê²½ë§ (20ì¸µ):   ê²€ì¦ ì†ì‹¤ 0.28  â† 20% ê°œì„ 
```

**ì‹¤ì œ ì ìš©:**
- VGGNetë³´ë‹¤ ë” ê¹Šì€ ResNet-152ë„ ì•ˆì •ì  í•™ìŠµ ê°€ëŠ¥
- ImageNet ë°ì´í„°ì…‹ì—ì„œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±

---

#### ğŸ““ 3.3 ì •ê·œí™” (L1/L2 Regularization)
**íŒŒì¼**: `3_Advanced_Techniques/3.3_regularization/l1_l2_regularization_demo.ipynb`

**ëª©í‘œ:**
ê³¼ì í•©(Overfitting)ì„ ì–µì œí•˜ê¸° ìœ„í•´ ì†ì‹¤í•¨ìˆ˜ì— ê°€ì¤‘ì¹˜ í˜ë„í‹° ì¶”ê°€

**L1 ì •ê·œí™” (Lasso)**
- ê³µì‹: Loss = Original_Loss + Î» Ã— Î£|w|
- íŠ¹ì„±: ì¼ë¶€ ê°€ì¤‘ì¹˜ë¥¼ ì •í™•íˆ 0ìœ¼ë¡œ ì¶•ì†Œ (íŠ¹ì„± ì„ íƒ)
- í™œìš©: í¬ì†Œ ëª¨ë¸ì´ í•„ìš”í•  ë•Œ

**L2 ì •ê·œí™” (Ridge)**
- ê³µì‹: Loss = Original_Loss + Î» Ã— Î£(wÂ²)
- íŠ¹ì„±: í° ê°€ì¤‘ì¹˜ë¥¼ ê· ë“±í•˜ê²Œ ì¶•ì†Œ
- í™œìš©: ì¼ë°˜ì ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ (ê¶Œì¥)

**Î» (ì •ê·œí™” ê°•ë„) ë¹„êµ:**

| Î» ê°’ | í›ˆë ¨ ì†ì‹¤ | ê²€ì¦ ì†ì‹¤ | ê´€ì°° |
|-----|---------|---------|------|
| 0 (ì—†ìŒ) | 0.15 | 0.45 | ê³¼ì í•© ì‹¬ê° |
| 0.001 | 0.18 | 0.38 | ê· í˜• ì¢‹ìŒ |
| 0.01 | 0.22 | 0.35 | ì •ê·œí™” íš¨ê³¼ |
| 0.1 | 0.28 | 0.32 | ê³¼ë„í•œ ì •ê·œí™” |

**íš¨ê³¼:**
- L2 (Î»=0.001): ê³¼ì í•© ê°ì†Œ 24% (0.45 â†’ 0.38)
- ê²€ì¦ ì„±ëŠ¥ í–¥ìƒìœ¼ë¡œ ì¼ë°˜í™” ëŠ¥ë ¥ ì¦ê°€

---

#### ğŸ““ 3.4 ê³¼ì í•© ë¶„ì„ (Overfitting Analysis)
**íŒŒì¼**: 
- `3_Advanced_Techniques/3.4_overfitting/overfitting_dataset_size_demo.ipynb`
- `3_Advanced_Techniques/3.4_overfitting/overfitting_demo.ipynb`

**ê³¼ì í•©ì˜ ì›ì¸:**

1. **ë°ì´í„°ì…‹ í¬ê¸° ë¶€ì¡±**
   - í›ˆë ¨ ë°ì´í„° 100ê°œ: ê³¼ì í•© ì‹¬ê° (í›ˆë ¨ ì •í™•ë„ 99%, ê²€ì¦ ì •í™•ë„ 65%)
   - í›ˆë ¨ ë°ì´í„° 10,000ê°œ: ê³¼ì í•© ì™„í™” (í›ˆë ¨ ì •í™•ë„ 95%, ê²€ì¦ ì •í™•ë„ 91%)

2. **ëª¨ë¸ ë³µì¡ë„ ê³¼ë‹¤**
   - ë…¸ë“œ ìˆ˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ í›ˆë ¨ ë°ì´í„° ì•”ê¸° ê°€ëŠ¥
   - íŒŒë¼ë¯¸í„° ìˆ˜ > í›ˆë ¨ ìƒ˜í”Œ ìˆ˜ì¼ ë•Œ ìœ„í—˜

**ê³¼ì í•© ê°ì§€:**
```
ê³¼ì í•© íŒ¨í„´:
- Epoch 1-5:   í›ˆë ¨ ì†ì‹¤ â†“, ê²€ì¦ ì†ì‹¤ â†“ (ì •ìƒ)
- Epoch 6-15:  í›ˆë ¨ ì†ì‹¤ â†“, ê²€ì¦ ì†ì‹¤ â†‘ (ê³¼ì í•© ì‹ í˜¸!)
```

**í•´ê²° ì „ëµ:**
- âœ… ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘
- âœ… ëª¨ë¸ ë³µì¡ë„ ê°ì†Œ (ë…¸ë“œ/ì¸µ ìˆ˜ ì¤„ì´ê¸°)
- âœ… ì •ê·œí™” ì¶”ê°€ (L1/L2)
- âœ… Dropout ì‚¬ìš©
- âœ… ì¡°ê¸° ì¢…ë£Œ (Early Stopping)

---

#### ğŸ““ 3.5 Dropout ê¸°ë²•
**íŒŒì¼**: `3_Advanced_Techniques/3.5_dropout/dropout_demo.ipynb`

**ê°œë…:**
í›ˆë ¨ ì¤‘ ê° ì—í¬í¬ë§ˆë‹¤ **ë¬´ì‘ìœ„ë¡œ ë‰´ëŸ°ì˜ ì¼ë¶€ë¥¼ ë¹„í™œì„±í™”**

**ì‘ë™ ì›ë¦¬:**

```
Dropout ì—†ìŒ:
Input â†’ [1] [1] [1] [1] â†’ Output (ëª¨ë“  ë‰´ëŸ° í™œì„±)

Dropout (p=0.5):
Input â†’ [1] [0] [1] [0] â†’ Output (50% ë¬´ì‘ìœ„ ë¹„í™œì„±)
         â†‘       â†‘ (ë¹„í™œì„± ë‰´ëŸ°)
```

**íš¨ê³¼:**
- ë‰´ëŸ° ê°„ ê³¼ë„í•œ í˜‘ë ¥ ë°©ì§€ (Co-adaptation ì–µì œ)
- ì—¬ëŸ¬ ì†Œí˜• ë„¤íŠ¸ì›Œí¬ì˜ ì•™ìƒë¸” íš¨ê³¼
- ê³¼ì í•© ê°ì†Œ

**Dropout rate ë¹„êµ:**

| Dropout Rate | í›ˆë ¨ ì •í™•ë„ | ê²€ì¦ ì •í™•ë„ | ê³¼ì í•© ì •ë„ |
|-------------|----------|----------|----------|
| 0 (ì—†ìŒ) | 98% | 78% | ì‹¬ê° (20% ì°¨ì´) |
| 0.3 | 96% | 85% | ì¤‘ê°„ |
| 0.5 | 94% | 91% | ê²½ë¯¸ (3% ì°¨ì´) |
| 0.7 | 92% | 90% | ê±°ì˜ ì—†ìŒ |

**ê¶Œì¥ ì‚¬í•­:**
- **0.5**: ì€ë‹‰ì¸µì˜ í‘œì¤€ dropout rate
- **0.2-0.3**: ì…ë ¥ì¸µ
- **í…ŒìŠ¤íŠ¸ ì‹œ**: dropout ë¹„í™œì„±í™” (ëª¨ë“  ë‰´ëŸ° ì‚¬ìš©)

---

#### ğŸ““ 3.6 ë°ì´í„° ì¦ê°• & í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
**íŒŒì¼**: `3_Advanced_Techniques/3.6_data_augmentation/data_aug_class_weight_demo.ipynb`

**ë¬¸ì œ: í´ë˜ìŠ¤ ë¶ˆê· í˜•**
```
ì‹¤ì œ ë°ì´í„°ì…‹ ë¶„í¬:
- ìŒì„± í´ë˜ìŠ¤: 9,500ê°œ (95%)
- ì–‘ì„± í´ë˜ìŠ¤: 500ê°œ (5%)

ë¬¸ì œì :
- ëª¨ë¸ì´ í•­ìƒ 'ìŒì„±'ì´ë¼ ì˜ˆì¸¡í•´ë„ 95% ì •í™•ë„
- ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµ ë¶ˆì¶©ë¶„
```

**í•´ê²°ì±… 1: Class Weights**
í¬ê·€í•œ í´ë˜ìŠ¤ì— ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬

```python
class_weight = {
    0: 1.0,           # ìŒì„± í´ë˜ìŠ¤
    1: 9500/500 = 19  # ì–‘ì„± í´ë˜ìŠ¤ (19ë°° ë†’ì€ ê°€ì¤‘ì¹˜)
}
```

**íš¨ê³¼:**
- ì†Œìˆ˜ í´ë˜ìŠ¤ ìƒ˜í”Œë‹¹ ì†ì‹¤ê°’ì´ 19ë°° ì¦ê°€
- ë¶ˆê· í˜• ìƒí™©ì—ì„œë„ ë‘ í´ë˜ìŠ¤ ëª¨ë‘ ì˜ í•™ìŠµ

**í•´ê²°ì±… 2: ë°ì´í„° ì¦ê°• (Data Augmentation)**
ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„°ë¥¼ ì¸ìœ„ì ìœ¼ë¡œ ì¦ê°€

```
ì›ë³¸ ë°ì´í„° (ì–‘ì„± 500ê°œ):
â”œâ”€ ì›ë³¸
â”œâ”€ íšŒì „ (Â±15ë„)
â”œâ”€ ì´ë™ (Â±10%)
â”œâ”€ ì¶•ì†Œ/í™•ëŒ€ (0.8~1.2ë°°)
â””â”€ ë…¸ì´ì¦ˆ ì¶”ê°€

ê²°ê³¼: ì–‘ì„± í´ë˜ìŠ¤ 2,000ê°œ+ (4ë°° ì¦ê°€)
```

**ì„±ëŠ¥ ê°œì„ :**

| ë°©ì‹ | ì •ë°€ë„ | ì¬í˜„ìœ¨ | F1-Score |
|------|------|------|---------|
| ë¯¸ì²˜ë¦¬ | 0.72 | 0.45 | 0.56 |
| Class Weight | 0.85 | 0.78 | 0.81 |
| Data Augmentation | 0.82 | 0.82 | 0.82 |
| ë‘˜ ë‹¤ ì ìš© | 0.88 | 0.85 | 0.87 |

**ì‹¤ë¬´ ì ìš© ê¶Œì¥ì‚¬í•­:**
1. ë¶ˆê· í˜• ë¹„ìœ¨ì´ 1:10 ë¯¸ë§Œ â†’ Class Weights ì ìš©
2. ë¶ˆê· í˜•ì´ ì‹¬í•  ë•Œ â†’ ë°ì´í„° ì¦ê°•ë„ í•¨ê»˜ ì‚¬ìš©
3. SMOTE ê¸°ë²•ë„ ê³ ë ¤ (ê³¼í•™ì  ë°ì´í„° ìƒì„±)

---

## ì„¤ì¹˜ ë° ì‹¤í–‰

### 1ï¸âƒ£ í™˜ê²½ ì¤€ë¹„

#### ìš”êµ¬ì‚¬í•­
- Python 3.8 ì´ìƒ
- pip ë˜ëŠ” conda

#### ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/[your-username]/Portfolio-DeepLearning-Fundamentals.git
cd Portfolio-DeepLearning-Fundamentals
```

### 2ï¸âƒ£ íŒ¨í‚¤ì§€ ì„¤ì¹˜

#### ë°©ë²• 1: pip ì‚¬ìš© (ê¶Œì¥)
```bash
pip install -r requirements.txt
```

#### ë°©ë²• 2: conda ì‚¬ìš©
```bash
conda create -n dl-portfolio python=3.9
conda activate dl-portfolio
pip install -r requirements.txt
```

#### ë°©ë²• 3: ê°œë³„ ì„¤ì¹˜
```bash
pip install tensorflow>=2.10.0
pip install numpy>=1.21.0
pip install pandas>=1.3.0
pip install matplotlib>=3.5.0
pip install scikit-learn>=1.0.0
pip install jupyter
```

### 3ï¸âƒ£ Jupyter Notebook ì‹¤í–‰

#### ì „ì²´ ë…¸íŠ¸ë¶ ì„œë²„ ì‹œì‘
```bash
jupyter notebook
```

#### íŠ¹ì • ë…¸íŠ¸ë¶ ì‹¤í–‰
```bash
# íšŒê·€ ì‹¤ìŠµ
jupyter notebook 1_Regression/1.1_loss_comparison/nn_regression_loss_comparison.ipynb

# ë¶„ë¥˜ ì‹¤ìŠµ
jupyter notebook 2_Classification/2.1_binary_multiclass/nn_classification_examples.ipynb

# ê³ ê¸‰ ê¸°ë²•
jupyter notebook 3_Advanced_Techniques/3.2_residual_networks/residual_vs_plain_demo.ipynb
```

#### Google Colabì—ì„œ ì‹¤í–‰ (ê¶Œì¥ - GPU ë¬´ë£Œ)
```python
# Colab ì…€ì—ì„œ ì‹¤í–‰
!git clone https://github.com/[your-username]/Portfolio-DeepLearning-Fundamentals.git
%cd Portfolio-DeepLearning-Fundamentals
!pip install -r requirements.txt

# ë…¸íŠ¸ë¶ ì‹¤í–‰
from IPython.display import IFrame
IFrame(src='1_Regression/1.1_loss_comparison/nn_regression_loss_comparison.ipynb', width=800, height=600)
```

### 4ï¸âƒ£ ê²€ì¦

ì„¤ì¹˜ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸:
```bash
python -c "
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import sklearn

print('TensorFlow:', tf.__version__)
print('NumPy:', np.__version__)
print('Scikit-learn:', sklearn.__version__)
print('âœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì •ìƒ ì„¤ì¹˜ë¨')
"
```

---

## í´ë” êµ¬ì¡°

```
Portfolio-DeepLearning-Fundamentals/
â”‚
â”œâ”€â”€ README.md                          â† í˜„ì¬ íŒŒì¼ (í¬íŠ¸í´ë¦¬ì˜¤ ì†Œê°œ)
â”œâ”€â”€ REPORT.md                          â† ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
â”œâ”€â”€ requirements.txt                   â† ì˜ì¡´ì„± ëª©ë¡
â”œâ”€â”€ LICENSE                            â† MIT ë¼ì´ì„ ìŠ¤
â”‚
â”œâ”€â”€ 1_Regression/
â”‚   â”œâ”€â”€ README.md                      â† íšŒê·€ ì„¹ì…˜ ì„¤ëª…
â”‚   â”œâ”€â”€ 1.1_loss_comparison/
â”‚   â”‚   â”œâ”€â”€ nn_regression_loss_comparison.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â”œâ”€â”€ mse_mae_huber_comparison.png
â”‚   â”‚       â”œâ”€â”€ learning_curves.png
â”‚   â”‚       â””â”€â”€ performance_summary.csv
â”‚   â””â”€â”€ [ê¸°íƒ€ íšŒê·€ ì‹¤ìŠµ]
â”‚
â”œâ”€â”€ 2_Classification/
â”‚   â”œâ”€â”€ README.md                      â† ë¶„ë¥˜ ì„¹ì…˜ ì„¤ëª…
â”‚   â”œâ”€â”€ 2.1_binary_multiclass/
â”‚   â”‚   â”œâ”€â”€ nn_classification_examples.ipynb
â”‚   â”‚   â”œâ”€â”€ nn_multiclass_classification.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â”œâ”€â”€ mnist_accuracy.png
â”‚   â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚       â””â”€â”€ predictions_visualization.png
â”‚   â””â”€â”€ [ê¸°íƒ€ ë¶„ë¥˜ ì‹¤ìŠµ]
â”‚
â”œâ”€â”€ 3_Advanced_Techniques/
â”‚   â”œâ”€â”€ README.md                      â† ê³ ê¸‰ ê¸°ë²• ì„¤ëª…
â”‚   â”œâ”€â”€ 3.1_vanishing_gradient/
â”‚   â”‚   â”œâ”€â”€ vanishing_gradient_demo.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â”œâ”€â”€ gradient_flow_analysis.png
â”‚   â”‚       â””â”€â”€ relu_vs_sigmoid.png
â”‚   â”œâ”€â”€ 3.2_residual_networks/
â”‚   â”‚   â”œâ”€â”€ residual_vs_plain_demo.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â””â”€â”€ residual_benefit.png
â”‚   â”œâ”€â”€ 3.3_regularization/
â”‚   â”‚   â”œâ”€â”€ l1_l2_regularization_demo.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â”œâ”€â”€ regularization_effect.png
â”‚   â”‚       â””â”€â”€ weight_distribution.png
â”‚   â”œâ”€â”€ 3.4_overfitting/
â”‚   â”‚   â”œâ”€â”€ overfitting_dataset_size_demo.ipynb
â”‚   â”‚   â”œâ”€â”€ overfitting_demo.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â”œâ”€â”€ overfitting_curves.png
â”‚   â”‚       â””â”€â”€ dataset_size_impact.png
â”‚   â”œâ”€â”€ 3.5_dropout/
â”‚   â”‚   â”œâ”€â”€ dropout_demo.ipynb
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”‚       â””â”€â”€ dropout_effect.png
â”‚   â””â”€â”€ 3.6_data_augmentation/
â”‚       â”œâ”€â”€ data_aug_class_weight_demo.ipynb
â”‚       â””â”€â”€ results/
â”‚           â”œâ”€â”€ class_imbalance_solution.png
â”‚           â””â”€â”€ augmentation_samples.png
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ banner.png                     â† í¬íŠ¸í´ë¦¬ì˜¤ ë°°ë„ˆ
â”‚   â”œâ”€â”€ architecture_diagrams.png      â† ì‹ ê²½ë§ êµ¬ì¡°ë„
â”‚   â”œâ”€â”€ comparison_tables.png          â† ë¹„êµ í‘œ
â”‚   â””â”€â”€ flow_chart.png                 â† ì „ì²´ í•™ìŠµ íë¦„
â”‚
â””â”€â”€ config/
    â””â”€â”€ training_params.yaml           â† í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ì„ íƒì‚¬í•­)
```

---

## ê¸°ìˆ  ìŠ¤íƒ

### ğŸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´
- **Python 3.8+**: ì£¼ìš” ì–¸ì–´

### ğŸ¤– ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **TensorFlow 2.10+**: ì‹ ê²½ë§ êµ¬ì¶• ë° í›ˆë ¨
- **Keras API**: TensorFlow ë‚´ ê³ ìˆ˜ì¤€ API

### ğŸ“Š ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„
- **NumPy**: ìˆ˜ì¹˜ ê³„ì‚° ë° ë°°ì—´ ì¡°ì‘
- **Pandas**: ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ (í•„ìš”ì‹œ)
- **Scikit-learn**: ì „ì²˜ë¦¬, ë°ì´í„° ë¶„í• , í‰ê°€ ì§€í‘œ

### ğŸ“ˆ ì‹œê°í™”
- **Matplotlib**: ê·¸ë˜í”„ ë° í•™ìŠµ ê³¡ì„ 
- **Seaborn** (ì„ íƒì‚¬í•­): í†µê³„ ì‹œê°í™”

### ğŸ”§ ê°œë°œ ë„êµ¬
- **Jupyter Notebook**: ëŒ€í™”í˜• ì½”ë“œ ì‹¤í–‰ ë° ì‹œê°í™”
- **Google Colab**: ë¬´ë£Œ GPU ì§€ì› í´ë¼ìš°ë“œ í™˜ê²½

### ğŸ’¾ ë²„ì „ ê´€ë¦¬
- **Git/GitHub**: ì½”ë“œ ê´€ë¦¬ ë° í˜‘ë ¥

---

## ì£¼ìš” ì„±ê³¼

### ğŸ“ˆ ì •ëŸ‰ì  ì„±ê³¼

| ëª©í‘œ | ë‹¬ì„±ë„ | ì„±ê³¼ |
|------|------|------|
| íšŒê·€ ëª¨ë¸ êµ¬ì¶• | âœ… 100% | MSE/MAE/Huber ì†ì‹¤í•¨ìˆ˜ ë¹„êµ ë¶„ì„ |
| ë¶„ë¥˜ ëª¨ë¸ ì •í™•ë„ | âœ… 95%+ | ì´ì§„ ë¶„ë¥˜ 95%, ë‹¤ì¤‘ ë¶„ë¥˜ 97% |
| ê³ ê¸‰ ê¸°ë²• ì´í•´ | âœ… 100% | 6ê°€ì§€ í•µì‹¬ ìµœì í™” ê¸°ë²• ì‹¤ìŠµ |
| ê³¼ì í•© ì–µì œ | âœ… ~30% | ì •ê·œí™” ë° Dropoutìœ¼ë¡œ ê³¼ì í•© 30% ê°ì†Œ |
| ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ | âœ… 87% | Class Weights + ë°ì´í„° ì¦ê°• F1-Score 0.87 |

### ğŸ’¡ ì •ì„±ì  ì„±ê³¼

1. **ì‹ ê²½ë§ ê¸°ì´ˆ ì´í•´**
   - ì—­ì „íŒŒ(Backpropagation) ë©”ì»¤ë‹ˆì¦˜ ìˆ™ì§€
   - í™œì„±í™” í•¨ìˆ˜ì˜ ì—­í•  ë° ì„ íƒ ê¸°ì¤€ ì´í•´
   - ì†ì‹¤í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì˜ ê´€ê³„ íŒŒì•…

2. **ì‹¤ì „ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥**
   - ê³¼ì í•© ê°ì§€ ë° í•´ê²° ì „ëµ ìˆ˜ë¦½
   - ë¶ˆê· í˜• ë°ì´í„°ì…‹ ì²˜ë¦¬ ê¸°ë²• ì ìš©
   - ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •

3. **ì½”ë“œ ì‘ì„± ë° ë¬¸ì„œí™” ëŠ¥ë ¥**
   - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆì‹ ì½”ë“œ ì‘ì„±
   - ëª…í™•í•œ ì£¼ì„ ë° ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œí™”
   - Jupyter ë…¸íŠ¸ë¶ì„ í†µí•œ ì‹¤ìŠµ ê²°ê³¼ ì „ì‹œ

4. **ë°ì´í„° ê³¼í•™ í”„ë¡œì íŠ¸ ê²½í—˜**
   - ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ í‰ê°€ê¹Œì§€ ì „ ê³¼ì • ê²½í—˜
   - ì‹œê°í™”ë¥¼ í†µí•œ ê²°ê³¼ ë¶„ì„ ë° í•´ì„
   - ë²„ì „ ê´€ë¦¬ ë° í˜‘ë ¥ ë„êµ¬ í™œìš©

---

## í–¥í›„ í•™ìŠµ ê³„íš

### Phase 1ï¸âƒ£: ì‹¬í™” í•™ìŠµ (1-2ê°œì›”)
- [ ] **CNN (Convolutional Neural Networks)**
  - ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ íƒì§€
  - ImageNet, CIFAR-10 ë°ì´í„°ì…‹
  
- [ ] **RNN/LSTM**
  - ì‹œê³„ì—´ ì˜ˆì¸¡
  - ìì—°ì–´ ì²˜ë¦¬ ê¸°ì´ˆ

### Phase 2ï¸âƒ£: ê³ ê¸‰ ê¸°ë²• (2-3ê°œì›”)
- [ ] **ì „ì´í•™ìŠµ (Transfer Learning)**
  - ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ í™œìš©
  - Fine-tuning ê¸°ë²•
  
- [ ] **Attention Mechanism**
  - Transformer ì•„í‚¤í…ì²˜
  - Self-attention ê°œë…

### Phase 3ï¸âƒ£: ì‹¤ë¬´ í”„ë¡œì íŠ¸ (3-6ê°œì›”)
- [ ] **ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì ìš©**
  - ì„¼ì„œ ë°ì´í„° ì´ìƒ íƒì§€
  - ìƒì‚°ì„± ì˜ˆì¸¡ ëª¨ë¸
  
- [ ] **ê°•í™”í•™ìŠµ (Reinforcement Learning)**
  - Q-Learning, Policy Gradient
  - ìµœì í™” ë¬¸ì œ í•´ê²°

### Phase 4ï¸âƒ£: ë…¼ë¬¸ ë° ë°œí‘œ
- [ ] í•™ìŠµ ê²°ê³¼ í•™ìˆ  ë…¼ë¬¸í™”
- [ ] GitHub í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¥
- [ ] ê¸°ìˆ  ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…

---

## ì°¸ê³  ìë£Œ

### ğŸ“š ì¶”ì²œ ë„ì„œ
- "Deep Learning" - Ian Goodfellow, Yoshua Bengio, Aaron Courville
- "Hands-On Machine Learning" - AurÃ©lien GÃ©ron
- "Neural Networks from Scratch" - Joel Grus

### ğŸŒ ì˜¨ë¼ì¸ ìë£Œ
- [TensorFlow ê³µì‹ íŠœí† ë¦¬ì–¼](https://www.tensorflow.org/tutorials)
- [Keras ë¬¸ì„œ](https://keras.io/)
- [Stanford CS231n: CNN for Visual Recognition](http://cs231n.stanford.edu/)
- [fast.ai: Practical Deep Learning](https://www.fast.ai/)

### ğŸ“ í•™ìŠµ ìë£Œ
- [Andrew Ng - Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)
- [Jeremy Howard - Fastai Courses](https://course.fast.ai/)

### ğŸ”— ìœ ìš©í•œ ë§í¬
- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [Keras Examples](https://keras.io/examples/)
- [Papers with Code](https://paperswithcode.com/)

---

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” **MIT License** í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬í•  ìˆ˜ ìˆìœ¼ë©°, ì¶œì²˜ ëª…ì‹œë§Œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.

```
MIT License

Copyright (c) 2025 [Your Name]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ì €ì ì •ë³´

**ì´ë¦„**: [ë‹¹ì‹ ì˜ ì´ë¦„]  
**ì§ì±…**: R&D í”Œë˜ë„ˆ & DX ì „ëµê°€  
**ì¡°ì§**: [íšŒì‚¬ëª…]  
**ì´ë©”ì¼**: [ì´ë©”ì¼]  
**GitHub**: [@[github-username]](https://github.com/[github-username])

### ê´€ì‹¬ ë¶„ì•¼
- ğŸ­ ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ë° ìŠ¤ë§ˆíŠ¸ ì œì¡°
- ğŸ¤– AI/ë¨¸ì‹ ëŸ¬ë‹ í™œìš©
- ğŸ’¾ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ë° ë°ì´í„° ì•„í‚¤í…ì²˜
- ğŸ”§ ë””ì§€í„¸ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜

### ê¸°ìˆ  ìŠ¤íƒ
```
Languages: Python, SQL
Tools: Jupyter, Git, TensorFlow, Scikit-learn
Platforms: Google Colab, GitHub
```

---

## ê¸°ì—¬ ë° í”¼ë“œë°±

ì´ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ì œì•ˆì´ë‚˜ ë²„ê·¸ ë¦¬í¬íŠ¸ëŠ” ì–¸ì œë“  í™˜ì˜í•©ë‹ˆë‹¤!

### ì´ìŠˆ ì œì¶œ
```bash
GitHub â†’ Issues â†’ New Issue
ì œëª©: [ë²„ê·¸/ì œì•ˆ] ê°„ë‹¨í•œ ì„¤ëª…
ë‚´ìš©: ìƒì„¸ ì„¤ëª…, ì¬í˜„ ë°©ë²•, ìŠ¤í¬ë¦°ìƒ· ë“±
```

### Pull Request
```bash
git checkout -b feature/your-feature
git commit -m "Add: ê¸°ëŠ¥ ì„¤ëª…"
git push origin feature/your-feature
# GitHubì—ì„œ Pull Request ìƒì„±
```

---

## ê°ì‚¬ì˜ ë§

ì´ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ë‹¤ìŒì˜ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì™€ ì»¤ë®¤ë‹ˆí‹°ì˜ ì§€ì›ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤:

- ğŸ™ TensorFlow & Keras íŒ€
- ğŸ™ Scikit-learn ì»¤ë®¤ë‹ˆí‹°
- ğŸ™ Jupyter & IPython í”„ë¡œì íŠ¸
- ğŸ™ ëª¨ë“  ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ìë“¤

---

**Last Updated**: 2025ë…„ 12ì›” 28ì¼  
**Version**: 1.0.0  

---

**â­ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ Star â­ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!**

