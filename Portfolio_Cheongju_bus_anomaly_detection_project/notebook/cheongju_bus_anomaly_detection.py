#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒ¨í„´ì¸ì‹_ì²­ì£¼_ë²„ìŠ¤ë…¸ì„ _ì´ìƒë°œìƒ_ê°ì§€_ì‹¤ìŠµ_ìµœì¢…_APIí‚¤ì œê±°.py

ì²­ì£¼ì‹œ ë²„ìŠ¤ë…¸ì„  ì´ìƒë°œìƒ ê°ì§€ ì‹¤ìŠµ (Tago API í‚¤ ì™„ì „ ì œê±° ë²„ì „)
ì‘ì„±ì¼: 2025-12-28
ì‘ì„±ì: R&D Planning Manager (Smart Factory DX Strategy)

ì‚¬ìš©ë²•:
1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •: export TAGO_KEY=ì‹¤ì œ_API_í‚¤
2. ì‹¤í–‰: python ì´íŒŒì¼ëª….py
"""

import os
import sys
import time
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib
matplotlib.use('Agg')  # ì„œë²„ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
import warnings
warnings.filterwarnings('ignore')

print("=== ì²­ì£¼ ë²„ìŠ¤ë…¸ì„  ì´ìƒë°œìƒ ê°ì§€ ë¶„ì„ ì‹œì‘ ===")

# =============================================================================
# 1. í™˜ê²½ ì„¤ì • ë° í•œê¸€ í°íŠ¸ ì ìš©
# =============================================================================

def setup_environment():
    """í™˜ê²½ ì„¤ì • ë° í•œê¸€ í°íŠ¸ ì„¤ì¹˜"""
    print("1. í™˜ê²½ ì„¤ì • ì¤‘...")
    
    # ì „ì—­ ìƒìˆ˜ (API í‚¤ ì™„ì „ ì œê±°)
    os.environ.setdefault('TAGO_KEY', 'YOUR_TAGO_API_KEY_HERE')
    global TAGO_KEY, CHEONGJU_CITY_CODE
    TAGO_KEY = os.getenv('TAGO_KEY', 'YOUR_TAGO_API_KEY_HERE')
    CHEONGJU_CITY_CODE = "33010"
    
    if TAGO_KEY == 'YOUR_TAGO_API_KEY_HERE':
        print("âš ï¸  [ê²½ê³ ] TAGO_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   export TAGO_KEY=ì‹¤ì œí‚¤ê°’ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
        print("   ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    try:
        # Ubuntu/Debian í•œê¸€ í°íŠ¸ ì„¤ì¹˜
        os.system('sudo apt-get update -qq > /dev/null 2>&1')
        os.system('sudo apt-get install -y fonts-nanum-extra -qq > /dev/null 2>&1')
        os.system('fc-cache -fv > /dev/null 2>&1')
        
        font_candidates = ["NanumGothic", "NanumBarunGothic", "Malgun Gothic", "DejaVu Sans"]
        
        # NanumGothic ì§ì ‘ ì¶”ê°€
        try:
            fm.fontManager.addfont("/usr/share/fonts/truetype/nanum/NanumGothic.ttf")
        except:
            pass
        
        # í°íŠ¸ ì„¤ì •
        nanum_path = fm.findfont("NanumGothic")
        if nanum_path:
            plt.rcParams["font.family"] = "NanumGothic"
            print(f"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: NanumGothic")
        else:
            for font_name in font_candidates:
                if font_name in [f.name for f in fm.fontManager.ttflist]:
                    plt.rcParams["font.family"] = font_name
                    print(f"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {font_name}")
                    break
            else:
                print("âš ï¸  ê¸°ë³¸ í°íŠ¸(DejaVu Sans) ì‚¬ìš©")
        
        plt.rcParams["axes.unicode_minus"] = False
        sns.set(style="whitegrid")
        
    except Exception as e:
        print(f"í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")

# =============================================================================
# 2. Tago API ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================

def tago_get(url, params):
    """Tago API í˜¸ì¶œ ë˜í¼"""
    if TAGO_KEY == 'YOUR_TAGO_API_KEY_HERE':
        print("âŒ API í‚¤ ì—†ìŒ. ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
        return None
    
    processed_url = url.strip()
    try:
        r = requests.get(processed_url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json()
        
        if not isinstance(data, dict):
            return None
        
        resp = data.get("response", {})
        header = resp.get("header", {})
        code = str(header.get("resultCode", ""))
        
        if code not in ("0", "00", "0000"):
            return None
        
        body = resp.get("body", {})
        if not isinstance(body, dict):
            return None
        
        return body
    except requests.exceptions.RequestException:
        return None

def get_city_codes():
    """ë„ì‹œì½”ë“œ ì¡°íšŒ"""
    url = "https://apis.data.go.kr/1613000/BusRouteInfoInqireService/getCtyCodeList"
    params = {
        "serviceKey": TAGO_KEY,
        "_type": "json",
        "numOfRows": 200,
        "pageNo": 1,
    }
    body = tago_get(url, params)
    if body is None:
        return pd.DataFrame()
    
    items = body.get("items", {}).get("item", [])
    if isinstance(items, dict):
        items = [items]
    return pd.DataFrame(items)

def get_cheongju_routes_all(page_size=200):
    """ì²­ì£¼ì‹œ ì „ì²´ ë²„ìŠ¤ ë…¸ì„  ì¡°íšŒ"""
    print("   ì²­ì£¼ ë²„ìŠ¤ ë…¸ì„  ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    url = "https://apis.data.go.kr/1613000/BusRouteInfoInqireService/getRouteNoList"
    all_items = []
    page = 1
    
    while True:
        params = {
            "serviceKey": TAGO_KEY,
            "cityCode": CHEONGJU_CITY_CODE,
            "_type": "json",
            "numOfRows": page_size,
            "pageNo": page,
            "routeNo": ""
        }
        
        body = tago_get(url, params)
        if body is None:
            break
        
        items_from_body = body.get("items", {})
        items = items_from_body.get("item", []) if isinstance(items_from_body, dict) else []
        
        if not items:
            break
        
        if isinstance(items, dict):
            all_items.append(items)
        else:
            all_items.extend(items)
        
        if len(items) < page_size:
            break
        page += 1
    
    if not all_items:
        print("   âš ï¸  API ë°ì´í„° ì—†ìŒ. ë”ë¯¸ ë…¸ì„  ë°ì´í„° ìƒì„±")
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        dummy_routes = []
        for i in range(50):
            dummy_routes.append({
                'routeid': f'CJB{i:03d}0001',
                'routeno': f'{100+i:03d}',
                'routetpnm': np.random.choice(['ê°„ì„ ', 'ì§€ì„ ', 'ìˆœí™˜']),
                'regionnm': 'ì²­ì£¼ì‹œ'
            })
        df = pd.DataFrame(dummy_routes)
    else:
        df = pd.DataFrame(all_items)
        if 'routeid' in df.columns:
            df['routeid'] = df['routeid'].astype(str)
    
    df.to_csv('cheongju_bus_routes.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ… ì²­ì£¼ ë…¸ì„  {len(df)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ -> cheongju_bus_routes.csv")
    return df

# =============================================================================
# 3. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
# =============================================================================

def collect_snapshots(route_df, n_routes=10, start_date="2024-01-01", num_days=7):
    """ë²„ìŠ¤ ìš´í–‰ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±"""
    print(f"2. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± ì¤‘... ({n_routes}ë…¸ì„  x {num_days}ì¼)")
    
    snapshot_list = []
    current_date_dt = datetime.strptime(start_date, '%Y-%m-%d')
    target_routes_df = route_df.head(n_routes)
    
    for day_offset in range(num_days):
        date_to_simulate = current_date_dt + timedelta(days=day_offset)
        is_weekend = date_to_simulate.weekday() >= 5
        
        for hour_of_day in range(24):
            ts = date_to_simulate.replace(hour=hour_of_day, minute=0, second=0).strftime("%Y-%m-%d %H:%M:%S")
            
            for _, row in target_routes_df.iterrows():
                rid = row["routeid"]
                routenm = row.get("routeno", "000")
                
                # ì‹œê°„ëŒ€ë³„ ë²„ìŠ¤ ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
                if is_weekend:
                    num_buses = np.random.randint(0, 4)
                else:
                    if 6 <= hour_of_day <= 20:
                        num_buses = np.random.randint(2, 8)
                    else:
                        num_buses = np.random.randint(0, 3)
                
                # ìœ„ì¹˜ ë°ì´í„° ìƒì„±
                positions = []
                for i in range(num_buses):
                    positions.append({
                        'gpslati': 36.63 + np.random.rand() * 0.05,
                        'gpslong': 127.49 + np.random.rand() * 0.05,
                        'vehicleno': f'BUS_{rid}_{hour_of_day}_{i}',
                        'routeid': rid,
                        'routenm': routenm
                    })
                
                df_pos = pd.DataFrame(positions)
                if df_pos.empty:
                    df_pos = pd.DataFrame({'routeid': [rid]})
                snapshot_list.append((ts, df_pos))
    
    print(f"   âœ… {len(snapshot_list)}ê°œ ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ")
    return snapshot_list

def build_route_hour_matrix(snapshot_list):
    """ë…¸ì„ -ì‹œê°„ í–‰ë ¬ ìƒì„±"""
    records = []
    for ts, df_pos in snapshot_list:
        dt = pd.to_datetime(ts)
        rid = df_pos['routeid'].iloc[0]
        num_veh = df_pos['vehicleno'].nunique() if 'vehicleno' in df_pos.columns else 0
        records.append({'routeid': rid, 'date': dt.date(), 'hour': dt.hour, 'num_veh': num_veh})
    
    if not records:
        return None, None
    
    df_data = pd.DataFrame(records)
    matrix = df_data.pivot_table(
        index=['routeid', 'date'], columns='hour', values='num_veh', aggfunc='first'
    ).fillna(0).reindex(columns=range(24), fill_value=0)
    
    return matrix, df_data

# =============================================================================
# 4. ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„
# =============================================================================

def analyze_anomalies(usage_matrix, n_clusters=8, contamination=0.1):
    """KMeans + IsolationForest ë¶„ì„"""
    print("3. ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(usage_matrix.values)
    
    # KMeans í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)
    
    # IsolationForest ì´ìƒê°ì§€
    iso = IsolationForest(n_estimators=200, contamination=contamination, random_state=42)
    anomalies = iso.predict(X_scaled)
    scores = iso.score_samples(X_scaled)
    
    result = pd.DataFrame({
        'routeid_date': usage_matrix.index.map(lambda x: f"{x[0]}_{x[1]}"),
        'cluster': clusters,
        'anomaly': anomalies,
        'score': scores
    }).set_index('routeid_date')
    
    return result

def add_insights(usage_matrix, result):
    """ì¸ì‚¬ì´íŠ¸ ì»¬ëŸ¼ ì¶”ê°€"""
    hour_cols = [col for col in usage_matrix.columns if isinstance(col, int)]
    insights = []
    
    for idx, row in result.iterrows():
        rid_date = idx.split('_')
        if len(rid_date) == 2:
            rid, date_str = rid_date
            date = pd.to_datetime(date_str).date()
            if (rid, date) in usage_matrix.index:
                row_data = usage_matrix.loc[(rid, date)]
                peak_ratio = row_data[hour_cols].max() / row_data[hour_cols].sum() if row_data.sum() > 0 else 0
            else:
                peak_ratio = 0
        
        insights.append({
            'cluster': row['cluster'],
            'anomaly': 'ì´ìƒ' if row['anomaly'] == -1 else 'ì •ìƒ',
            'score': row['score'],
            'peak_ratio': peak_ratio
        })
    
    insight_df = pd.DataFrame(insights, index=result.index)
    
    def get_comment(row):
        if row['anomaly'] == 'ì´ìƒ':
            if row['peak_ratio'] > 0.5:
                return "íŠ¹ì •ì‹œê°„ëŒ€_ìˆ˜ìš”ê¸‰ì¦_ì¦ì°¨ê²€í† "
            return "íŒ¨í„´ì´ìƒ_ìš´ì˜ì ê²€í•„ìš”"
        return "ì •ìƒ"
    
    insight_df['comment'] = insight_df.apply(get_comment, axis=1)
    return insight_df

# =============================================================================
# 5. ì‹œê°í™”
# =============================================================================

def create_plots(usage_matrix, insights, n_clusters=8):
    """ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
    print("4. ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # 1. í´ëŸ¬ìŠ¤í„° íŒ¨í„´
    plt.figure(figsize=(12, 6))
    hours = range(24)
    for c in range(n_clusters):
        cluster_routes = insights[insights['cluster'] == c].index
        if len(cluster_routes) > 0:
            routes_idx = []
            for rt in cluster_routes:
                rid, date = rt.split('_')
                routes_idx.append((rid, pd.to_datetime(date).date()))
            if routes_idx:
                mean_pattern = usage_matrix.loc[routes_idx].mean()
                plt.plot(hours, mean_pattern, marker='o', label=f'Cluster {c}')
    plt.title('í´ëŸ¬ìŠ¤í„°ë³„ 24ì‹œê°„ ìš´í–‰ íŒ¨í„´')
    plt.xlabel('ì‹œê°„ëŒ€')
    plt.ylabel('í‰ê·  ì°¨ëŸ‰ìˆ˜')
    plt.legend()
    plt.grid(True)
    plt.savefig('cluster_patterns.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. ì´ìƒ ì ìˆ˜ ë¶„í¬
    plt.figure(figsize=(8, 5))
    sns.histplot(insights['score'], bins=20, kde=True)
    plt.title('ì´ìƒ ì ìˆ˜ ë¶„í¬')
    plt.xlabel('ì´ìƒì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì´ìƒ)')
    plt.savefig('anomaly_scores.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. ìƒìœ„ ì´ìƒ ë…¸ì„ 
    top_anomalies = insights[insights['anomaly'] == 'ì´ìƒ'].nsmallest(10, 'score')
    plt.figure(figsize=(12, 6))
    sns.barplot(data=top_anomalies.reset_index(), x='routeid_date', y='score')
    plt.title('ìƒìœ„ 10ê°œ ì´ìƒ ë…¸ì„ ')
    plt.xticks(rotation=45)
    plt.savefig('top_anomalies.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   âœ… ì°¨íŠ¸ ì €ì¥ ì™„ë£Œ: cluster_patterns.png, anomaly_scores.png, top_anomalies.png")

# =============================================================================
# 6. ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # í™˜ê²½ ì„¤ì •
        setup_environment()
        
        # 1. ë…¸ì„  ë°ì´í„° ìˆ˜ì§‘
        routes = get_cheongju_routes_all()
        
        # 2. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        snapshots = collect_snapshots(routes)
        usage_matrix, raw_data = build_route_hour_matrix(snapshots)
        
        if usage_matrix is None or usage_matrix.empty:
            print("âŒ ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
            return
        
        # 3. ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„
        result = analyze_anomalies(usage_matrix)
        insights = add_insights(usage_matrix, result)
        
        # 4. ê²°ê³¼ ì €ì¥
        insights.to_csv('cheongju_bus_anomaly_results.csv', encoding='utf-8-sig')
        usage_matrix.to_csv('usage_matrix.csv')
        raw_data.to_csv('raw_snapshots.csv', encoding='utf-8-sig')
        
        # 5. ì‹œê°í™”
        create_plots(usage_matrix, insights)
        
        print("\n" + "="*60)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print("="*60)
        print("ìƒì„±ëœ íŒŒì¼:")
        print("  ğŸ“„ cheongju_bus_routes.csv      - ë…¸ì„  ê¸°ë³¸ì •ë³´")
        print("  ğŸ“„ cheongju_bus_anomaly_results.csv - ì´ìƒê°ì§€ ê²°ê³¼")
        print("  ğŸ“„ usage_matrix.csv             - ì‚¬ìš© í–‰ë ¬")
        print("  ğŸ“„ raw_snapshots.csv            - ì›ë³¸ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°")
        print("  ğŸ–¼ï¸  cluster_patterns.png        - í´ëŸ¬ìŠ¤í„° íŒ¨í„´")
        print("  ğŸ–¼ï¸  anomaly_scores.png          - ì´ìƒì ìˆ˜ ë¶„í¬")
        print("  ğŸ–¼ï¸  top_anomalies.png           - ìƒìœ„ ì´ìƒ ë…¸ì„ ")
        print("\nì‚¬ìš©ë²•: export TAGO_KEY=ì‹¤ì œí‚¤ê°’ í›„ ì¬ì‹¤í–‰")
        
        # ìš”ì•½ í†µê³„
        anomalies_count = (insights['anomaly'] == 'ì´ìƒ').sum()
        print(f"\nğŸ“Š ë¶„ì„ ìš”ì•½:")
        print(f"   ì´ ë…¸ì„ -ì¼ì: {len(insights):,}")
        print(f"   ì´ìƒ ê°ì§€: {anomalies_count:,}ê±´ ({anomalies_count/len(insights)*100:.1f}%)")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
